{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutaition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 2 text mining***\n",
    "\n",
    "For this exercise, we will not use example code. Instead, you will write the code yourself based on the kind of code that you before. See the Cookbook for reference.\n",
    "\n",
    "See the documentation of sklearn.naive_bayes_MultinomialNB for the Naive Bayes model object.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Import the relevant libraries and/or objects\n",
    "2. Split the data into a training and a test set\n",
    "3. Train a NB model on the training set\n",
    "4. Predict the class (Lisa or Bart) of the test set.\n",
    "5. What is the accuracy of your model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('simpsons.csv')\n",
    "df = df.loc[(df['raw_character_text'] == 'Lisa Simpson') | (df['raw_character_text'] == 'Bart Simpson')]\n",
    "text = df['spoken_words'].values.astype('U') #Taking the text from the df. We need to convert it to Unicode\n",
    "vect = CountVectorizer(stop_words='english') #Create the CV object, with English stop words\n",
    "vect = vect.fit(text) #We fit the model with the words from the review text\n",
    "docu_feat = vect.transform(text) # make a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6403960396039604"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB() #create the model\n",
    "X = docu_feat #the document-feature matrix is the X matrix\n",
    "y = df['raw_character_text'] #creating the y vector\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) #split the data and store it\n",
    "\n",
    "nb = nb.fit(X_train, y_train) #fit the model X=features, y=character\n",
    "\n",
    "#Evaluate the model\n",
    "y_test_p = nb.predict(X_test)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bart Simpson    0.544954\n",
       "Lisa Simpson    0.455046\n",
       "Name: raw_character_text, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['raw_character_text'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise 3 text mining***\n",
    "\n",
    "In this exercise we will evaluate the model and delve further into the data. Remember that you can use the Cookbook for examples of code.\n",
    "\n",
    "1. Start where you left off. Create a confusion matrix.\n",
    "2. Calculate the accuracy and the recall and precision for both Bart and Lisa.\n",
    "3. Check out the documentation on how to get the probabilities for a certain text belonging to a class (tip: itâ€™s a method), instead of a categorization. Try it on a line of dialogue.\n",
    "4. Create a loop that prints out a few lines of dialogue and the associated probabilities for Bart and Lisa. Tip: the array with the probabilities is 2-dimensional.\n",
    "5. Check out the output. Do you see patterns (based on the data and your knowledge of the Simpsons)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d9f21dcda818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
